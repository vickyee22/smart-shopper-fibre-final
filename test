import gradio as gr
from guardrails import is_off_topic, is_salutation
import os
import requests
import json
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENSEARCH_HOST = os.getenv("OPENSEARCH_HOST")
OPENSEARCH_USER = os.getenv("OPENSEARCH_USER")
OPENSEARCH_PASS = os.getenv("OPENSEARCH_PASS")
INDEX_NAME = "smartshopper-index"

client = OpenAI(api_key=OPENAI_API_KEY)

def fetch_clarification_question(intent, sub_status, step):
    query = {
        "size": 1,
        "query": {
            "bool": {
                "must": [
                    {"term": {"metadata.intent": intent}},
                    {"term": {"metadata.sub_status": sub_status}},
                    {"term": {"metadata.sequence": step + 1}}
                ]
            }
        }
    }

    res = requests.get(
        f"{OPENSEARCH_HOST}/clarifications/_search",
        auth=(OPENSEARCH_USER, OPENSEARCH_PASS),
        headers={"Content-Type": "application/json"},
        json=query
    )

    if res.status_code != 200:
        print(f"[DEBUG] Clarification fetch failed: {res.status_code}")
        return None

    hits = res.json().get("hits", {}).get("hits", [])
    if not hits:
        print("[DEBUG] No clarification question found.")
        return None

    return hits[0]["_source"]["text"]


def detect_emotion(text):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": "Classify the user's emotional tone as one of: neutral, frustration, or positive. "
                           "Treat complaints about price, speed, or dissatisfaction as frustration."
            },
            {
                "role": "user",
                "content": f'What is the emotional tone of: "{text}"?'
            }
        ]
    )
    emotion = response.choices[0].message.content.strip().lower()
    print(f"[DEBUG] Emotion detected: {emotion}")
    return emotion


CLARIFICATION_QUESTIONS = {
    "fibre": {
        "recontract": [
            "Are you experiencing issues with your current fibre plan?",
            "Do you need faster speed or better stability?",
            "Would you like to bundle with other services for more value?"
        ],
        "new_line": [
            "What's the size of your home or number of rooms?",
            "How many people will be using the internet at home?",
            "Are you a heavy user for gaming or streaming?"
        ]
    },
    "mobile": {
        "recontract": [
            "Are you looking to recontract with or without a new phone?",
            "Has your data or usage needs changed?",
            "What’s your priority: price, more data, or phone upgrade?"
        ],
        "new_line": [
            "How much data do you need per month?",
            "Do you prefer a contract or no contract?",
            "What’s your monthly budget?"
        ]
    }
}

user_context = {}

def embed_text(text):
    response = client.embeddings.create(
        model="text-embedding-ada-002",
        input=[text]
    )
    return response.data[0].embedding

def detect_primary_intent_vector(message, threshold=0.5):
    vector = embed_text(message)
    query = {
        "size": 1,
        "query": {
            "knn": {
                "embedding": {
                    "vector": vector,
                    "k": 1
                }
            }
        }
    }
    print(f"[DEBUG] Sending vector search for intent: {message}")
    res = requests.get(
        f"{OPENSEARCH_HOST}/{INDEX_NAME}/_search",
        auth=(OPENSEARCH_USER, OPENSEARCH_PASS),
        headers={"Content-Type": "application/json"},
        json=query
    )
    print(f"[DEBUG] OpenSearch response status: {res.status_code}")
    if res.status_code != 200:
        print(f"[ERROR] OpenSearch response: {res.status_code}")
        return "unknown"
    hits = res.json().get("hits", {}).get("hits", [])
    if not hits:
        print("[DEBUG] No matches found.")
        return "unknown"

    print(f"[DEBUG] Vector match: {hits[0]['_source']['text']} | Score: {hits[0]['_score']}")
    if hits[0]["_score"] < threshold:
        print("[DEBUG] Match score too low.")
        return "unknown"
    return hits[0]["_source"]["metadata"]["intent"]

def chat(message, history):
    user_id = "default_user"
    if user_id not in user_context:
        print("[DEBUG] Initializing new user context")
        user_context[user_id] = {"primary": None, "sub_status": None, "step": 0, "telco_clarified": False}

    context = user_context[user_id]

    # ✅ Salutation check first
    if is_salutation(message):
        return {
            "role": "assistant",
            "content": "Hi there! I’m here to help you find the best Singtel broadband or mobile plan. What are you looking for today?"
        }

    # Guardrail check
    if not context["primary"]:
        
        print("[DEBUG] No primary intent yet. Checking off-topic...")
        primary = detect_primary_intent_vector(message)
        if primary == "unknown":
            if is_off_topic(message):
                print("[DEBUG] Detected off-topic, exiting.")
                return {
                    "role": "assistant",
                    "content": "Apologies, I'm here specifically to help you explore Singtel broadband and mobile plans. Let me know how I can assist with that!"
                }

        context["primary"] = primary

        emotion = detect_emotion(message).strip().lower()
        print(f"[DEBUG] Detected emotion: {emotion}")

        if "frustration" in emotion:
            tone = f"Sorry to hear that! Let's explore better {primary} options for you."
        elif "positive" in emotion:
            tone = f"Awesome! Let's help you find the right {primary} plan."
        else:
            tone = f"Thanks for sharing. You're looking for {primary} plans."

        return {
            "role": "assistant",
            "content": f"{tone} Are you currently with Singtel or switching from another provider?"
        }

    # Clarify if user is recontracting or new
    print(f"[DEBUG] Telco clarification not done yet. User message: {message}")
    if not context["telco_clarified"]:
        if "singtel" in message.lower():
            context["sub_status"] = "recontract"
        else:
            context["sub_status"] = "new_line"
        context["telco_clarified"] = True
        question = CLARIFICATION_QUESTIONS[context["primary"]][context["sub_status"]][0]
        return {
            "role": "assistant",
            "content": f"Thanks for confirming! Let's get started.\n\n{question}"
        }

    # Proceed with clarification questions
    step = context["step"]
    primary = context["primary"]
    sub_status = context["sub_status"]
    questions = CLARIFICATION_QUESTIONS[primary][sub_status]
    question = fetch_clarification_question(primary, sub_status, step)
    if not question:
        print('[DEBUG] No more clarification questions.')
        return {"role": "assistant", "content": "Thanks! Let me summarize your needs and recommend a suitable plan."}
    context["step"] += 1
    return {"role": "assistant", "content": question}
    context["step"] += 1

    if context["step"] < len(questions):
        return {"role": "assistant", "content": questions[context["step"]]}

    # All questions answered → final recommendation
    user_answers = [msg["content"] for msg in history if msg["role"] == "user"][-len(questions):]
    qna_pairs = "\n\n".join([
        f"Q{i+1}: {questions[i]}\nA{i+1}: {user_answers[i]}" for i in range(len(questions))
    ])
    prompt = (
        f"A customer answered the following about their {sub_status.replace('_',' ')} {primary} plan needs:\n\n"
        f"{qna_pairs}\n\n"
        f"Recommend the most suitable Singtel plan with a short reason."
    )

    try:
        with open("prompts.json", "r") as f:
            system_prompt = json.load(f)["system_prompt"]

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ]
        )
        reply = response.choices[0].message.content.strip()
        print(f"[DEBUG] Final GPT reply: {reply}")

    except Exception as e:
        reply = f"Error: {str(e)}"

    print("[DEBUG] Resetting user context")
    user_context[user_id] = {"primary": None, "sub_status": None, "step": 0, "telco_clarified": False}
    return {"role": "assistant", "content": reply}

# Gradio UI
gr.ChatInterface(
    fn=chat,
    title="Singtel Smart Shopper Assistant",
    type="messages"
).launch()
